{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyyaml==5.1\n",
      "  Downloading PyYAML-5.1.tar.gz (274 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: pyyaml\n",
      "  Building wheel for pyyaml (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pyyaml: filename=PyYAML-5.1-cp312-cp312-macosx_11_0_arm64.whl size=44092 sha256=6e1290fc9eddd6e5a1c607cb72ea3ce6298415323e36c980731e00d0f6f894b2\n",
      "  Stored in directory: /Users/shuai/Library/Caches/pip/wheels/77/56/3d/ecbc52138290af7ae8703dabe02cede143ab9cea349cf1aef3\n",
      "Successfully built pyyaml\n",
      "Installing collected packages: pyyaml\n",
      "  Attempting uninstall: pyyaml\n",
      "    Found existing installation: PyYAML 6.0.2\n",
      "    Uninstalling PyYAML-6.0.2:\n",
      "      Successfully uninstalled PyYAML-6.0.2\n",
      "Successfully installed pyyaml-5.1\n",
      "Cloning into 'detectron2'...\n",
      "remote: Enumerating objects: 15832, done.\u001b[K\n",
      "remote: Counting objects: 100% (46/46), done.\u001b[K\n",
      "remote: Compressing objects: 100% (32/32), done.\u001b[K\n",
      "remote: Total 15832 (delta 24), reused 16 (delta 14), pack-reused 15786 (from 3)\u001b[K\n",
      "Receiving objects: 100% (15832/15832), 6.40 MiB | 10.19 MiB/s, done.\n",
      "Resolving deltas: 100% (11529/11529), done.\n",
      "Ignoring dataclasses: markers 'python_version < \"3.7\"' don't match your environment\n",
      "Requirement already satisfied: Pillow>=7.1 in /Users/shuai/miniconda3/envs/blast/lib/python3.12/site-packages (11.0.0)\n",
      "Requirement already satisfied: matplotlib in /Users/shuai/miniconda3/envs/blast/lib/python3.12/site-packages (3.10.0)\n",
      "Requirement already satisfied: pycocotools>=2.0.2 in /Users/shuai/miniconda3/envs/blast/lib/python3.12/site-packages (2.0.8)\n",
      "Requirement already satisfied: termcolor>=1.1 in /Users/shuai/miniconda3/envs/blast/lib/python3.12/site-packages (2.5.0)\n",
      "Collecting yacs>=0.1.8\n",
      "  Downloading yacs-0.1.8-py3-none-any.whl.metadata (639 bytes)\n",
      "Collecting tabulate\n",
      "  Downloading tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\n",
      "Collecting cloudpickle\n",
      "  Using cached cloudpickle-3.1.0-py3-none-any.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: tqdm>4.29.0 in /Users/shuai/miniconda3/envs/blast/lib/python3.12/site-packages (4.67.1)\n",
      "Collecting tensorboard\n",
      "  Using cached tensorboard-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting fvcore<0.1.6,>=0.1.5\n",
      "  Downloading fvcore-0.1.5.post20221221.tar.gz (50 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting iopath<0.1.10,>=0.1.7\n",
      "  Downloading iopath-0.1.9-py3-none-any.whl.metadata (370 bytes)\n",
      "Collecting omegaconf<2.4,>=2.1\n",
      "  Downloading omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting hydra-core>=1.1\n",
      "  Downloading hydra_core-1.3.2-py3-none-any.whl.metadata (5.5 kB)\n",
      "Collecting black\n",
      "  Downloading black-24.10.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (79 kB)\n",
      "Requirement already satisfied: packaging in /Users/shuai/miniconda3/envs/blast/lib/python3.12/site-packages (24.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/shuai/miniconda3/envs/blast/lib/python3.12/site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/shuai/miniconda3/envs/blast/lib/python3.12/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/shuai/miniconda3/envs/blast/lib/python3.12/site-packages (from matplotlib) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/shuai/miniconda3/envs/blast/lib/python3.12/site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: numpy>=1.23 in /Users/shuai/miniconda3/envs/blast/lib/python3.12/site-packages (from matplotlib) (2.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/shuai/miniconda3/envs/blast/lib/python3.12/site-packages (from matplotlib) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/shuai/miniconda3/envs/blast/lib/python3.12/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: PyYAML in /Users/shuai/miniconda3/envs/blast/lib/python3.12/site-packages (from yacs>=0.1.8) (5.1)\n",
      "Collecting absl-py>=0.4 (from tensorboard)\n",
      "  Using cached absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting grpcio>=1.48.2 (from tensorboard)\n",
      "  Downloading grpcio-1.68.1-cp312-cp312-macosx_10_9_universal2.whl.metadata (3.9 kB)\n",
      "Collecting markdown>=2.6.8 (from tensorboard)\n",
      "  Using cached Markdown-3.7-py3-none-any.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /Users/shuai/miniconda3/envs/blast/lib/python3.12/site-packages (from tensorboard) (5.29.2)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /Users/shuai/miniconda3/envs/blast/lib/python3.12/site-packages (from tensorboard) (75.1.0)\n",
      "Requirement already satisfied: six>1.9 in /Users/shuai/miniconda3/envs/blast/lib/python3.12/site-packages (from tensorboard) (1.17.0)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard)\n",
      "  Using cached tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard)\n",
      "  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting portalocker (from iopath<0.1.10,>=0.1.7)\n",
      "  Downloading portalocker-3.0.0-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting antlr4-python3-runtime==4.9.* (from omegaconf<2.4,>=2.1)\n",
      "  Using cached antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting click>=8.0.0 (from black)\n",
      "  Using cached click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting mypy-extensions>=0.4.3 (from black)\n",
      "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting pathspec>=0.9.0 (from black)\n",
      "  Downloading pathspec-0.12.1-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: platformdirs>=2 in /Users/shuai/miniconda3/envs/blast/lib/python3.12/site-packages (from black) (4.3.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/shuai/miniconda3/envs/blast/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard) (3.0.2)\n",
      "Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
      "Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Using cached cloudpickle-3.1.0-py3-none-any.whl (22 kB)\n",
      "Using cached tensorboard-2.18.0-py3-none-any.whl (5.5 MB)\n",
      "Downloading iopath-0.1.9-py3-none-any.whl (27 kB)\n",
      "Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
      "Downloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n",
      "Downloading black-24.10.0-cp312-cp312-macosx_11_0_arm64.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "Using cached click-8.1.7-py3-none-any.whl (97 kB)\n",
      "Downloading grpcio-1.68.1-cp312-cp312-macosx_10_9_universal2.whl (11.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.1/11.1 MB\u001b[0m \u001b[31m34.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached Markdown-3.7-py3-none-any.whl (106 kB)\n",
      "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Downloading pathspec-0.12.1-py3-none-any.whl (31 kB)\n",
      "Using cached tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Downloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "Downloading portalocker-3.0.0-py3-none-any.whl (19 kB)\n",
      "Building wheels for collected packages: fvcore, antlr4-python3-runtime\n",
      "  Building wheel for fvcore (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for fvcore: filename=fvcore-0.1.5.post20221221-py3-none-any.whl size=61396 sha256=d512249ddf9e17dc2c2eb7738de04e9ea43da6c222b1e371779226679fd42b8a\n",
      "  Stored in directory: /Users/shuai/Library/Caches/pip/wheels/ed/9f/a5/e4f5b27454ccd4596bd8b62432c7d6b1ca9fa22aef9d70a16a\n",
      "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144555 sha256=0e19f22c0dd6c040a16dafad160e8098c23120eb48d58a7268764dd4082f24f1\n",
      "  Stored in directory: /Users/shuai/Library/Caches/pip/wheels/1f/be/48/13754633f1d08d1fbfc60d5e80ae1e5d7329500477685286cd\n",
      "Successfully built fvcore antlr4-python3-runtime\n",
      "Installing collected packages: antlr4-python3-runtime, yacs, werkzeug, tensorboard-data-server, tabulate, portalocker, pathspec, omegaconf, mypy-extensions, markdown, grpcio, cloudpickle, click, absl-py, tensorboard, iopath, hydra-core, black, fvcore\n",
      "Successfully installed absl-py-2.1.0 antlr4-python3-runtime-4.9.3 black-24.10.0 click-8.1.7 cloudpickle-3.1.0 fvcore-0.1.5.post20221221 grpcio-1.68.1 hydra-core-1.3.2 iopath-0.1.9 markdown-3.7 mypy-extensions-1.0.0 omegaconf-2.3.0 pathspec-0.12.1 portalocker-3.0.0 tabulate-0.9.0 tensorboard-2.18.0 tensorboard-data-server-0.7.2 werkzeug-3.1.3 yacs-0.1.8\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install pyyaml==5.1\n",
    "import sys, os, distutils.core\n",
    "# Note: This is a faster way to install detectron2 in Colab, but it does not include all functionalities (e.g. compiled operators).\n",
    "# See https://detectron2.readthedocs.io/tutorials/install.html for full installation instructions\n",
    "!git clone 'https://github.com/facebookresearch/detectron2'\n",
    "dist = distutils.core.run_setup(\"./detectron2/setup.py\")\n",
    "!python -m pip install {' '.join([f\"'{x}'\" for x in dist.install_requires])}\n",
    "sys.path.insert(0, os.path.abspath('./detectron2'))\n",
    "\n",
    "# Properly install detectron2. (Please do not install twice in both ways)\n",
    "# !python -m pip install 'git+https://github.com/facebookresearch/detectron2.git'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: nvcc\n",
      "torch:  2.5 ; cuda:  2.5.1\n",
      "detectron2: 0.6\n"
     ]
    }
   ],
   "source": [
    "import sys, os, distutils.core\n",
    "sys.path.insert(0, os.path.abspath('./detectron2'))\n",
    "\n",
    "import torch, detectron2\n",
    "!nvcc --version\n",
    "TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n",
    "CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n",
    "print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)\n",
    "print(\"detectron2:\", detectron2.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some basic setup:\n",
    "# Setup detectron2 logger\n",
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "# import some common libraries\n",
    "import numpy as np\n",
    "import os, json, cv2, random\n",
    "\n",
    "# import some common detectron2 utilities\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.data.datasets import register_coco_instances\n",
    "register_coco_instances(\"my_dataset_train\", {\"mask_format\": \"bitmask\"}, \"/Users/shuai/Desktop/Mining/Dataset/Labling Job/train_dataset_coco/annotations.json\", \"/Users/shuai/Desktop/Mining/Dataset/Labling Job/train_dataset_coco\")\n",
    "register_coco_instances(\"my_dataset_val2\", {\"mask_format\": \"bitmask\"}, \"/Users/shuai/Desktop/Mining/Dataset/Labling Job/val_dataset_coco/annotations.json\", \"/Users/shuai/Desktop/Mining/Dataset/Labling Job/val_dataset_coco\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.engine import DefaultTrainer\n",
    "\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "cfg.DATASETS.TRAIN = (\"my_dataset_train\",)\n",
    "cfg.DATASETS.TEST = ()\n",
    "cfg.DATALOADER.NUM_WORKERS = 2\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")  # Let training initialize from model zoo\n",
    "cfg.SOLVER.IMS_PER_BATCH = 2  # This is the real \"batch size\" commonly known to deep learning people\n",
    "cfg.SOLVER.BASE_LR = 0.00025  # pick a good LR\n",
    "cfg.SOLVER.MAX_ITER = 300    # 300 iterations seems good enough for this toy dataset; you will need to train longer for a practical dataset\n",
    "cfg.SOLVER.STEPS = []        # do not decay learning rate\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128   # The \"RoIHead batch size\". 128 is faster, and good enough for this toy dataset (default: 512)\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1  # only has one class (ballon). (see https://detectron2.readthedocs.io/tutorials/datasets.html#update-the-config-for-new-datasets)\n",
    "cfg.MODEL.DEVICE = \"cpu\"\n",
    "# NOTE: this config means the number of classes, but a few popular unofficial tutorials incorrect uses num_classes+1 here.\n",
    "\n",
    "cfg.INPUT.MASK_FORMAT = \"bitmask\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/19 23:07:02 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=2, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[12/19 23:07:02 d2.data.datasets.coco]: \u001b[0mLoaded 5 images in COCO format from /Users/shuai/Desktop/Mining/Dataset/Labling Job/train_dataset_coco/annotations.json\n",
      "\u001b[32m[12/19 23:07:02 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 5 images left.\n",
      "\u001b[32m[12/19 23:07:02 d2.data.build]: \u001b[0mDistribution of instances among all 1 categories:\n",
      "\u001b[36m|  category  | #instances   |\n",
      "|:----------:|:-------------|\n",
      "|   smoke    | 79           |\n",
      "|            |              |\u001b[0m\n",
      "\u001b[32m[12/19 23:07:02 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[12/19 23:07:02 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[12/19 23:07:02 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[12/19 23:07:02 d2.data.common]: \u001b[0mSerializing 5 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/19 23:07:02 d2.data.common]: \u001b[0mSerialized dataset takes 0.02 MiB\n",
      "\u001b[32m[12/19 23:07:02 d2.data.build]: \u001b[0mMaking batched data loader with batch_size=2\n",
      "\u001b[32m[12/19 23:07:02 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from https://dl.fbaipublicfiles.com/detectron2/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x/137849600/model_final_f10217.pkl ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (2, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (2,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (4, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (4,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (1, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (1,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.mask_head.predictor.{bias, weight}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/19 23:07:02 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shuai/Desktop/Mining/dev/detectron2/detectron2/data/detection_utils.py:449: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:212.)\n",
      "  torch.stack([torch.from_numpy(np.ascontiguousarray(x)) for x in masks])\n",
      "/Users/shuai/Desktop/Mining/dev/detectron2/detectron2/data/detection_utils.py:449: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:212.)\n",
      "  torch.stack([torch.from_numpy(np.ascontiguousarray(x)) for x in masks])\n",
      "/Users/shuai/miniconda3/envs/blast/lib/python3.12/site-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3596.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/19 23:08:11 d2.utils.events]: \u001b[0m eta: 0:15:40  iter: 19  total_loss: 3.1  loss_cls: 0.6834  loss_box_reg: 0.8815  loss_mask: 0.6915  loss_rpn_cls: 0.5657  loss_rpn_loc: 0.27    time: 3.3348  last_time: 3.4799  data_time: 0.0767  last_data_time: 0.0011   lr: 1.6068e-05  \n",
      "\u001b[32m[12/19 23:09:17 d2.utils.events]: \u001b[0m eta: 0:14:35  iter: 39  total_loss: 2.581  loss_cls: 0.6196  loss_box_reg: 0.8774  loss_mask: 0.6828  loss_rpn_cls: 0.1401  loss_rpn_loc: 0.2213    time: 3.3079  last_time: 3.1015  data_time: 0.0014  last_data_time: 0.0013   lr: 3.2718e-05  \n",
      "\u001b[32m[12/19 23:10:21 d2.utils.events]: \u001b[0m eta: 0:13:28  iter: 59  total_loss: 2.282  loss_cls: 0.5256  loss_box_reg: 0.8075  loss_mask: 0.6626  loss_rpn_cls: 0.0629  loss_rpn_loc: 0.263    time: 3.2822  last_time: 3.4071  data_time: 0.0013  last_data_time: 0.0017   lr: 4.9367e-05  \n",
      "\u001b[32m[12/19 23:11:27 d2.utils.events]: \u001b[0m eta: 0:12:21  iter: 79  total_loss: 2.237  loss_cls: 0.4781  loss_box_reg: 0.8309  loss_mask: 0.6293  loss_rpn_cls: 0.05558  loss_rpn_loc: 0.2033    time: 3.2843  last_time: 3.4199  data_time: 0.0014  last_data_time: 0.0012   lr: 6.6017e-05  \n",
      "\u001b[32m[12/19 23:12:30 d2.utils.events]: \u001b[0m eta: 0:11:10  iter: 99  total_loss: 2.147  loss_cls: 0.4406  loss_box_reg: 0.8533  loss_mask: 0.5914  loss_rpn_cls: 0.04617  loss_rpn_loc: 0.2123    time: 3.2551  last_time: 3.5236  data_time: 0.0013  last_data_time: 0.0013   lr: 8.2668e-05  \n",
      "\u001b[32m[12/19 23:13:36 d2.utils.events]: \u001b[0m eta: 0:10:05  iter: 119  total_loss: 1.967  loss_cls: 0.3979  loss_box_reg: 0.8201  loss_mask: 0.5418  loss_rpn_cls: 0.03594  loss_rpn_loc: 0.1931    time: 3.2658  last_time: 3.4403  data_time: 0.0014  last_data_time: 0.0012   lr: 9.9318e-05  \n",
      "\u001b[32m[12/19 23:14:41 d2.utils.events]: \u001b[0m eta: 0:08:56  iter: 139  total_loss: 1.86  loss_cls: 0.3514  loss_box_reg: 0.8278  loss_mask: 0.481  loss_rpn_cls: 0.0381  loss_rpn_loc: 0.1647    time: 3.2650  last_time: 3.4043  data_time: 0.0014  last_data_time: 0.0017   lr: 0.00011597  \n",
      "\u001b[32m[12/19 23:15:50 d2.utils.events]: \u001b[0m eta: 0:07:49  iter: 159  total_loss: 1.677  loss_cls: 0.2997  loss_box_reg: 0.7827  loss_mask: 0.4276  loss_rpn_cls: 0.03078  loss_rpn_loc: 0.1497    time: 3.2839  last_time: 4.0672  data_time: 0.0014  last_data_time: 0.0014   lr: 0.00013262  \n",
      "\u001b[32m[12/19 23:16:57 d2.utils.events]: \u001b[0m eta: 0:06:44  iter: 179  total_loss: 1.545  loss_cls: 0.2721  loss_box_reg: 0.7342  loss_mask: 0.3708  loss_rpn_cls: 0.0253  loss_rpn_loc: 0.1365    time: 3.2946  last_time: 3.4369  data_time: 0.0014  last_data_time: 0.0011   lr: 0.00014927  \n",
      "\u001b[32m[12/19 23:18:06 d2.utils.events]: \u001b[0m eta: 0:05:38  iter: 199  total_loss: 1.461  loss_cls: 0.2689  loss_box_reg: 0.664  loss_mask: 0.3129  loss_rpn_cls: 0.02068  loss_rpn_loc: 0.1371    time: 3.3073  last_time: 3.5161  data_time: 0.0013  last_data_time: 0.0012   lr: 0.00016592  \n",
      "\u001b[32m[12/19 23:19:10 d2.utils.events]: \u001b[0m eta: 0:04:30  iter: 219  total_loss: 1.249  loss_cls: 0.2311  loss_box_reg: 0.5715  loss_mask: 0.2678  loss_rpn_cls: 0.02384  loss_rpn_loc: 0.1266    time: 3.3006  last_time: 3.4733  data_time: 0.0014  last_data_time: 0.0014   lr: 0.00018257  \n",
      "\u001b[32m[12/19 23:20:17 d2.utils.events]: \u001b[0m eta: 0:03:22  iter: 239  total_loss: 1.181  loss_cls: 0.2231  loss_box_reg: 0.5078  loss_mask: 0.2636  loss_rpn_cls: 0.01818  loss_rpn_loc: 0.1341    time: 3.3020  last_time: 3.5268  data_time: 0.0014  last_data_time: 0.0012   lr: 0.00019922  \n",
      "\u001b[32m[12/19 23:21:22 d2.utils.events]: \u001b[0m eta: 0:02:14  iter: 259  total_loss: 1.128  loss_cls: 0.2232  loss_box_reg: 0.4495  loss_mask: 0.2447  loss_rpn_cls: 0.01501  loss_rpn_loc: 0.109    time: 3.2969  last_time: 3.2577  data_time: 0.0014  last_data_time: 0.0015   lr: 0.00021587  \n",
      "\u001b[32m[12/19 23:22:28 d2.utils.events]: \u001b[0m eta: 0:01:07  iter: 279  total_loss: 1.002  loss_cls: 0.1977  loss_box_reg: 0.416  loss_mask: 0.2329  loss_rpn_cls: 0.01326  loss_rpn_loc: 0.1013    time: 3.2994  last_time: 3.0388  data_time: 0.0014  last_data_time: 0.0015   lr: 0.00023252  \n",
      "\u001b[32m[12/19 23:23:33 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 299  total_loss: 0.9636  loss_cls: 0.2108  loss_box_reg: 0.3652  loss_mask: 0.2217  loss_rpn_cls: 0.01803  loss_rpn_loc: 0.1072    time: 3.2956  last_time: 3.4647  data_time: 0.0014  last_data_time: 0.0011   lr: 0.00024917  \n",
      "\u001b[32m[12/19 23:23:33 d2.engine.hooks]: \u001b[0mOverall training speed: 298 iterations in 0:16:22 (3.2956 s / it)\n",
      "\u001b[32m[12/19 23:23:33 d2.engine.hooks]: \u001b[0mTotal training time: 0:16:22 (0:00:00 on hooks)\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "trainer = DefaultTrainer(cfg) \n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6007 (pid 90429), started 0:00:33 ago. (Use '!kill 90429' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-48d8a8e29ac5bf92\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-48d8a8e29ac5bf92\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6007;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Look at training curves in tensorboard:\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/19 23:45:46 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from ./output/model_final.pth ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shuai/miniconda3/envs/blast/lib/python3.12/site-packages/fvcore/common/checkpoint.py:252: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(f, map_location=torch.device(\"cpu\"))\n"
     ]
    }
   ],
   "source": [
    "# Inference should use the config with parameters that are used in training\n",
    "# cfg now already contains everything we've set previously. We changed it a little bit for inference:\n",
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")  # path to the model we just trained\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7   # set a custom testing threshold\n",
    "predictor = DefaultPredictor(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/20 01:08:27 d2.data.datasets.coco]: \u001b[0mLoaded 2 images in COCO format from /Users/shuai/Desktop/Mining/Dataset/Labling Job/val_dataset_coco/annotations.json\n",
      "pred_boxes: Boxes(tensor([[ 852.2872,  324.3633,  931.4574,  480.2841],\n",
      "        [ 820.7631,  425.8528,  875.2355,  488.3456],\n",
      "        [ 699.7626,  404.8133,  748.9818,  471.7026],\n",
      "        [ 416.7763,  444.4831,  445.9590,  488.6767],\n",
      "        [ 517.1619,  413.8363,  550.4404,  468.5389],\n",
      "        [ 924.9492,  403.3569,  961.2749,  464.1497],\n",
      "        [1178.8324,  342.2535, 1274.7996,  487.0500]]))\n",
      "pred_boxes: Boxes(tensor([[ 777.1945,  194.1928,  902.4446,  487.1743],\n",
      "        [ 946.6554,  401.0926,  998.2261,  470.3513],\n",
      "        [1066.6348,  446.6577, 1146.5656,  595.9115],\n",
      "        [ 470.1970,  320.8749,  528.8103,  470.1872],\n",
      "        [ 363.2117,  357.7937,  459.0234,  522.9763],\n",
      "        [ 821.9166,  503.9017,  873.4849,  562.8269],\n",
      "        [ 903.7746,  346.5542,  945.5742,  461.3372],\n",
      "        [ 542.6726,  443.5585,  574.6830,  482.6411]]))\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from detectron2.utils.visualizer import ColorMode\n",
    "from detectron2.data import DatasetCatalog\n",
    "\n",
    "# Load the dataset as dataset_dicts\n",
    "dataset_dicts = DatasetCatalog.get(\"my_dataset_val2\")\n",
    "my_dataset_metadata = MetadataCatalog.get(\"my_dataset_val2\")\n",
    "\n",
    "# Load the homography matrix from npy\n",
    "H = np.load(\"homography_matrix.npy\")\n",
    "\n",
    "for d in random.sample(dataset_dicts, 2):    \n",
    "    im = cv2.imread(d[\"file_name\"])\n",
    "    outputs = predictor(im)  # format is documented at https://detectron2.readthedocs.io/tutorials/models.html#model-output-format\n",
    "    v = Visualizer(im[:, :, ::-1],\n",
    "                   metadata=my_dataset_metadata, \n",
    "                   scale=1, \n",
    "                   instance_mode=ColorMode.IMAGE_BW   # remove the colors of unsegmented pixels. This option is only available for segmentation models\n",
    "    )\n",
    "    out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "    output_image = np.array(out.get_image()[:, :, ::-1], dtype=np.uint8)\n",
    "\n",
    "    # Retrieve bounding boxes and classes\n",
    "    pred_boxes = outputs[\"instances\"].pred_boxes\n",
    "    pred_classes = outputs[\"instances\"].pred_classes\n",
    "\n",
    "    print(\"pred_boxes:\", pred_boxes)\n",
    "\n",
    "    for box in pred_boxes.to(\"cpu\"):\n",
    "        x_min, y_min, x_max, y_max = box.numpy()\n",
    "\n",
    "        # Bottom-center of the bounding box in the original image\n",
    "        center_x = (x_min + x_max) / 2\n",
    "        center_y = y_max\n",
    "\n",
    "        # Radius of the circle (half the width of the bounding box)\n",
    "        radius = int((x_max - x_min) / 2)\n",
    "\n",
    "        # Set the major axis equal to the bounding box width\n",
    "        major_axis_length = x_max - x_min\n",
    "\n",
    "        # Define a vertical point for the minor axis calculation\n",
    "        vertical_point = np.array([center_x, center_y - radius, 1])  # Point directly upward\n",
    "\n",
    "        # Apply homography to the center and the vertical axis point\n",
    "        warped_center = H @ np.array([center_x, center_y, 1])\n",
    "        warped_vertical = H @ vertical_point\n",
    "\n",
    "        # Normalize homogeneous coordinates\n",
    "        warped_center /= warped_center[2]\n",
    "        warped_vertical /= warped_vertical[2]\n",
    "\n",
    "        # Calculate the minor axis length (distance from center to warped vertical point)\n",
    "        minor_axis_length = 2 * np.linalg.norm(warped_vertical[:2] - warped_center[:2])  # Double for full axis\n",
    "\n",
    "        # Draw the ellipse with the original position and adjusted axes\n",
    "        cv2.ellipse(\n",
    "            output_image,\n",
    "            (int(center_x), int(center_y)),  # Original center\n",
    "            (int(major_axis_length / 2), int(minor_axis_length / 2)),  # Half-lengths of axes\n",
    "            0,  # No rotation needed\n",
    "            0, 360,  # Full ellipse\n",
    "            (0, 0, 255),  # Red color\n",
    "            thickness=2\n",
    "        )\n",
    "\n",
    "\n",
    "    design_map = cv2.imread(\"drill_hole_map.png\", cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "    output_image = cv2.cvtColor(output_image, cv2.COLOR_BGR2BGRA)\n",
    "\n",
    "    # Warp the design map to align with the drone footage\n",
    "    aligned_map = cv2.warpPerspective(design_map, H, (output_image.shape[1], output_image.shape[0]), flags=cv2.INTER_LINEAR, borderMode=cv2.BORDER_CONSTANT, borderValue=(0, 0, 0, 0))\n",
    "\n",
    "    # Blend the aligned design map onto the drone image\n",
    "    # Normalize alpha channel of the aligned map\n",
    "    alpha_map = aligned_map[:, :, 3] / 255.0  # Normalized alpha values (0.0 to 1.0)\n",
    "\n",
    "    # Blend each channel (R, G, B)\n",
    "    for c in range(3):  # Iterate over the R, G, B channels\n",
    "        output_image[:, :, c] = (\n",
    "            alpha_map * aligned_map[:, :, c] + (1 - alpha_map) * output_image[:, :, c]\n",
    "        ).astype(np.uint8)\n",
    "\n",
    "    # Combine the alpha channels: keep the maximum alpha for each pixel\n",
    "    output_image[:, :, 3] = np.maximum(output_image[:, :, 3], aligned_map[:, :, 3])\n",
    "        \n",
    "\n",
    "    output_filename = \"output_\" + os.path.basename(d[\"file_name\"])\n",
    "    success = cv2.imwrite(output_filename, output_image)\n",
    "    if not success:\n",
    "        print(\"Failed to save the image.\")\n",
    "    # cv2.imshow(\"Predictions\", out.get_image()[:, :, ::-1])\n",
    "    # cv2.waitKey(0)\n",
    "    # cv2.destroyAllWindows()\n",
    "\n",
    "    # # Display the image\n",
    "    # im = cv2.cvtColor(out.get_image()[:, :, ::-1], cv2.COLOR_BGR2RGB)\n",
    "    # plt.imshow(im)\n",
    "    # plt.axis('off')  # Turn off axes for better display\n",
    "    # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "blast",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
